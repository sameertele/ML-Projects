{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "05a57ec9-745f-4589-ae8d-8ac5a7721fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "360bf935-51bd-4cfb-b8f7-1099fdc3a32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "78742c23-e301-46ad-930b-14fb4dbc559b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The MNIST dataset has input features of 28x28. We need 32x32 so converting it to that.\n",
    "train_images = tf.pad(train_images, [[0, 0], [2,2], [2,2]])/255\n",
    "test_images = tf.pad(test_images, [[0, 0], [2,2], [2,2]])/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "27218eef-b4d8-44d7-ad3e-23314ab65914",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = tf.expand_dims(train_images, axis=3, name=None)\n",
    "test_images = tf.expand_dims(test_images, axis=3, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9dfbbd24-67c8-4943-aa8c-036a59a19522",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(tf.Module):\n",
    "    def __init__(self):\n",
    "        self.conv1 = tf.Variable(tf.random.normal([5, 5, 1, 6]))\n",
    "        self.bias1 = tf.Variable(tf.random.normal([6]))\n",
    "        self.conv2 = tf.Variable(tf.random.normal([5, 5, 6, 16]))\n",
    "        self.bias2 = tf.Variable(tf.random.normal([16]))\n",
    "        self.final_pooling = tf.Variable(tf.random.normal([5 * 5 * 16, 120]))\n",
    "        self.bias3 = tf.Variable(tf.random.normal([120]))\n",
    "        self.fc1 = tf.Variable(tf.random.normal([120, 84]))\n",
    "        self.bias4 = tf.Variable(tf.random.normal([84]))\n",
    "        self.fc2 = tf.Variable(tf.random.normal([84, 10]))\n",
    "        self.bias5 = tf.Variable(tf.random.normal([10]))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = tf.nn.conv2d(x, self.conv1, strides=1, padding='VALID') + self.bias1\n",
    "        x = tf.nn.tanh(x)\n",
    "        x = tf.nn.avg_pool(x, ksize=2, strides=2, padding='VALID')\n",
    "\n",
    "        x = tf.nn.conv2d(x, self.conv2, strides=1, padding='VALID') + self.bias2\n",
    "        x = tf.nn.tanh(x)\n",
    "        x = tf.nn.avg_pool(x, ksize=2, strides=2, padding='VALID')\n",
    "\n",
    "        x = tf.reshape(x, (-1, 5 * 5 * 16))\n",
    "\n",
    "        x = tf.matmul(x, self.final_pooling) + self.bias3\n",
    "        x = tf.nn.tanh(x)\n",
    "\n",
    "        x = tf.matmul(x, self.fc1) + self.bias4\n",
    "        x = tf.nn.tanh(x)\n",
    "\n",
    "        logits = tf.matmul(x, self.fc2) + self.bias5\n",
    "        probabilities = tf.nn.softmax(logits)  \n",
    "        return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d7c57c9f-a5f3-4336-b3d7-532b61992391",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet5()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c39a0956-ef76-4f15-9979-75bb2cb7276d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "86e3a300-bc31-4909-b46f-5b9f236eac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_crossentropy(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.int64)\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "loss_object = sparse_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4668abd2-406e-4b73-95a1-31d41c8ff6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.9219536781311035, Accuracy: 0.5027166604995728\n",
      "Epoch 2, Loss: 1.8210641145706177, Accuracy: 0.593583345413208\n",
      "Epoch 3, Loss: 1.8380365371704102, Accuracy: 0.6223166584968567\n",
      "Epoch 4, Loss: 1.756899118423462, Accuracy: 0.6869000196456909\n",
      "Epoch 5, Loss: 1.546610713005066, Accuracy: 0.7529833316802979\n",
      "Epoch 6, Loss: 1.5719115734100342, Accuracy: 0.7829833626747131\n",
      "Epoch 7, Loss: 1.5677082538604736, Accuracy: 0.7882000207901001\n",
      "Epoch 8, Loss: 1.5819745063781738, Accuracy: 0.7941499948501587\n",
      "Epoch 9, Loss: 1.5599223375320435, Accuracy: 0.8023499846458435\n",
      "Epoch 10, Loss: 1.5687637329101562, Accuracy: 0.8097333312034607\n",
      "Epoch 11, Loss: 1.5793914794921875, Accuracy: 0.8156499862670898\n",
      "Epoch 12, Loss: 1.5246639251708984, Accuracy: 0.8607666492462158\n",
      "Epoch 13, Loss: 1.5275018215179443, Accuracy: 0.8978999853134155\n",
      "Epoch 14, Loss: 1.465390682220459, Accuracy: 0.9088000059127808\n",
      "Epoch 15, Loss: 1.4732043743133545, Accuracy: 0.9146333336830139\n",
      "Epoch 16, Loss: 1.5252611637115479, Accuracy: 0.9139000177383423\n",
      "Epoch 17, Loss: 1.4995778799057007, Accuracy: 0.9209666848182678\n",
      "Epoch 18, Loss: 1.5252430438995361, Accuracy: 0.9231833219528198\n",
      "Epoch 19, Loss: 1.4611562490463257, Accuracy: 0.926716685295105\n",
      "Epoch 20, Loss: 1.4633903503417969, Accuracy: 0.9268333315849304\n",
      "Epoch 21, Loss: 1.4671401977539062, Accuracy: 0.9311500191688538\n",
      "Epoch 22, Loss: 1.4612069129943848, Accuracy: 0.9319333434104919\n",
      "Epoch 23, Loss: 1.462071418762207, Accuracy: 0.9352333545684814\n",
      "Epoch 24, Loss: 1.4618728160858154, Accuracy: 0.9386500120162964\n",
      "Epoch 25, Loss: 1.4612822532653809, Accuracy: 0.9365500211715698\n",
      "Epoch 26, Loss: 1.4864170551300049, Accuracy: 0.9367833137512207\n",
      "Epoch 27, Loss: 1.4615404605865479, Accuracy: 0.9388166666030884\n",
      "Epoch 28, Loss: 1.461150884628296, Accuracy: 0.942883312702179\n",
      "Epoch 29, Loss: 1.4616403579711914, Accuracy: 0.945816695690155\n",
      "Epoch 30, Loss: 1.4611984491348267, Accuracy: 0.9444166421890259\n"
     ]
    }
   ],
   "source": [
    "#Training the data\n",
    "epochs = 30\n",
    "batch_size = 64\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, len(train_images), batch_size):\n",
    "        batch_images = train_images[i:i + batch_size]\n",
    "        batch_labels = train_labels[i:i + batch_size]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(batch_images)\n",
    "            loss = loss_object(batch_labels, logits)\n",
    "\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_logits = model(train_images)\n",
    "    train_predicted = tf.argmax(train_logits, axis=1, output_type=tf.int32)\n",
    "    train_accuracy = tf.reduce_mean(tf.cast(tf.equal(train_predicted, train_labels), dtype=tf.float32))\n",
    "    print(f'Epoch {epoch + 1}, Loss: {loss.numpy()}, Accuracy: {train_accuracy.numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7a550438-1454-47bb-8753-d0490301b3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test Accuracy: 0.9416000247001648\n"
     ]
    }
   ],
   "source": [
    "#Testing the data\n",
    "test_logits = model(test_images)\n",
    "predictions = tf.argmax(test_logits, axis=1, output_type=tf.int32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predictions, test_labels), dtype=tf.float32))\n",
    "print(f' Test Accuracy: {accuracy.numpy()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
